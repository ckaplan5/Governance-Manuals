<?xml version="1.0" encoding="utf-8"?>
<html xmlns:MadCap="http://www.madcapsoftware.com/Schemas/MadCap.xsd">
    <head><title></title>
        <link href="../Resources/Stylesheets/Training.css" rel="stylesheet" />
    </head>
    <body>
        <h2 class="Heading2"><a name="_Toc417653066"></a>End to End Remediation </h2>
        <p class="ScreenShot_4" style="text-align: center;">
            <img src="../Resources/Images/Information Steward Accelerator Fundamentals (6.2)/End to End Remediation.png" style="visibility: visible;mso-wrap-style: square;width: 451px;height: 424px;" />
        </p>
        <p class="ScreenShot_4" style="text-align: center;">&#160;</p>
        <h2 class="Heading2"><a name="_Toc417653067"></a>Information Steward Accelerator Solution</h2>
        <p style="margin-top: 3pt;margin-bottom: 3pt;">The key components, within the ISA Solution, that are necessary to remediate failed data based on rules defined in Information Steward are:</p>
        <ul style="list-style-type: disc;margin-left: 18pt;">
            <li class="ListBullet_2" style="list-style-type: disc;"><span style="font-weight: bold;">Information Steward Accelerator</span> - ISA extracts data that failed Information Steward (IS) rules, then distributes the data to groups of users. These user groups, called Project Distributions, can receive the data as an Excel file (.xlsx) attached to an email or can view a summary of the rule’s data.</li>
        </ul>
        <p class="ListBullet_2">Project Distributions, along with users, have rules and bindings. These rules have associated Quality Dimensions by which rules are grouped. Filters can be applied at the user or project distribution level to filter the data sets sent to specific user groups.</p>
        <ul style="list-style-type: disc;margin-left: 18pt;">
            <li class="ListBullet_2" style="list-style-type: disc;"><span style="font-weight: bold;">Collect - </span>A data repository management component that is a core entity of many DSP™ product offerings. Collect maintains a unified collection of data from multiple, disparate systems without requiring users to connect to the actual systems. Generally, in production it will run on scheduled intervals and at an individual table level. In this way, the data can be kept in sync based on the processing schedule of each data source. Collect also contains import groups to organize and manage sets of tables.</li>
        </ul>
    </body>
</html>